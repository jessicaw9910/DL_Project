{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb72af71",
   "metadata": {},
   "source": [
    "# ChemVAE Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3bbdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "from model import ConvEncoder, GRUDecoder, ChemVAE\n",
    "from trainer import train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613b891",
   "metadata": {},
   "source": [
    "## Import and Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248c30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input = '../data/zinc.csv'\n",
    "args_train = 1000\n",
    "args_val = 100\n",
    "args_output = True\n",
    "args_colc = 'SMILES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee188f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 training index conversion errors\n",
      "There are 0 testing index conversion errors\n",
      "\n",
      "There are 0 training one-hot conversion errors\n",
      "There are 0 testing one-hot conversion errors\n"
     ]
    }
   ],
   "source": [
    "# GitHub data directory contains only tar.gz version\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('../data/zinc.tar.gz', compression='gzip', header=0, sep=',', error_bad_lines=False)\n",
    "# df.columns[0] = 'SMILES'\n",
    "\n",
    "df = import_data(args_input)\n",
    "X_train, X_test = return_splits(df, n_train=args_train, n_test=args_val, col_chem=args_colc)\n",
    "char2idx, idx2char, train_idx, test_idx = create_data(X_train, X_test, colname=args_colc)   \n",
    "train_oh, test_oh = check_conversions(idx2char, train_idx, X_train, test_idx, X_test)\n",
    "\n",
    "# print(max([len(i) for i in X_train]))\n",
    "# print(max([len(i) for i in X_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00275576",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_lr = 0.001\n",
    "args_dynlr = True\n",
    "args_batch_size = 10 #200\n",
    "## per GoÃÅmez-Bombarelli Zinc GRU hidden dim 488\n",
    "args_latent_size = 488\n",
    "arg_seed = 123\n",
    "args_model_path = '../weights/' + args_colc + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8975af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_length = train_oh.shape[1]\n",
    "n_char = train_oh.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fa60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = \"cpu\"\n",
    "\n",
    "enc = ConvEncoder(args_latent_size, n_length, n_char).to(device)\n",
    "dec = GRUDecoder(args_latent_size, n_length, n_char).to(device)\n",
    "model = ChemVAE(enc, dec).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args_lr)\n",
    "if args_dynlr:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', \n",
    "                                                           factor = 0.8, \n",
    "                                                           patience = 3,\n",
    "                                                           min_lr = 0.0001)\n",
    "\n",
    "X_train = torch.from_numpy(train_oh.astype(np.float32))\n",
    "X_test = torch.from_numpy(test_oh.astype(np.float32))\n",
    "\n",
    "torch.manual_seed(arg_seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, \n",
    "                                           batch_size=args_batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=6,\n",
    "                                           drop_last = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, \n",
    "                                          batch_size=args_batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=6,\n",
    "                                          drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd9ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train() called: model=ChemVAE, opt=Adam(lr=0.001000), epochs=100, device=cuda:0\n",
      "\n",
      "Epoch   1/100, train loss: 140.14, train acc:  0.53, val loss: 117.47, val acc:  0.59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9c7e6a43ea87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\PhD\\NYU\\Deep Learning\\project\\github\\src\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, scheduler, dl_train, dl_val, path, device, epochs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mX_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mbce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\PhD\\NYU\\Deep Learning\\project\\github\\src\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_logvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_logvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\PhD\\NYU\\Deep Learning\\project\\github\\src\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mout_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0my0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl_project\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 850\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    851\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train(model, optimizer, scheduler, train_loader, test_loader, args_model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d8f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3efc5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7149db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231afa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "80dc7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_idx = list(output.argmax(axis=2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "95d8e1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 11, 11, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        4, 26, 26, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0611c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_char = [convert_num2str(i, idx2char) for i in output_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3c7fb331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCccccccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccc11',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccccccc',\n",
       " 'CCccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccc1',\n",
       " 'CCcccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccccccc1',\n",
       " 'CCccccccccccccccccccccccccccccccc',\n",
       " 'CCcccccccccccccccccccccccccccccccc']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6ec9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fc378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02905d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layer):\n",
    "    '''\n",
    "    Initialize weights based on layer type\n",
    "    \n",
    "    Args:\n",
    "        layer (torch.nn): neural network whose weights to initialize\n",
    "    '''\n",
    "    if type(layer) == nn.Conv1d:\n",
    "        init.normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if type(layer) == nn.Linear:\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)\n",
    "    if type(layer) == nn.GRU:\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09606af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7df934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
